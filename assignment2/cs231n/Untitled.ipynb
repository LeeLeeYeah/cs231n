{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dout\n",
      "[[4 1]\n",
      " [3 3]]\n",
      "weight\n",
      "[[[1 2]\n",
      "  [3 0]]\n",
      "\n",
      " [[0 3]\n",
      "  [2 1]]]\n",
      "In\n",
      "iteration..\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[2 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[16  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[22  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[12  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[16  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 2 12  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[16  3  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [ 8  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [18  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [20  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [34  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [17  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [29  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [18 15  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [18 25  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [34 14  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [34 28  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [29 27  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [29 41  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [18 25 10]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [18 25 14]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [34 28  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [34 28  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [29 41  4]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [29 41  8]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [18 25 14]\n",
      " [ 6  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [18 25 14]\n",
      " [18  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [34 28  0]\n",
      " [ 6  0  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [34 28  0]\n",
      " [10  0  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [29 41  8]\n",
      " [ 6  0  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [29 41  8]\n",
      " [14  0  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [18 25 14]\n",
      " [18  9  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [18 25 14]\n",
      " [18 15  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [34 28  0]\n",
      " [10  6  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [34 28  0]\n",
      " [10 24  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [29 41  8]\n",
      " [14 18  0]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [29 41  8]\n",
      " [14 26  0]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [18 25 14]\n",
      " [18 15  3]]\n",
      "iteration..\n",
      "[[ 2 16  3]\n",
      " [18 25 14]\n",
      " [18 15  3]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [34 28  0]\n",
      " [10 24  0]]\n",
      "iteration..\n",
      "[[22  4  0]\n",
      " [34 28  0]\n",
      " [10 24  8]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [29 41  8]\n",
      " [14 26 12]]\n",
      "iteration..\n",
      "[[16  7  0]\n",
      " [29 41  8]\n",
      " [14 26 14]]\n",
      "iteration..\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[4 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[7 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[3 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[5 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[1 3 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[1 9 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[7 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[5 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[ 5 10  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[1 9 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[1 9 8]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 10  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[1 9 8]\n",
      " [2 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[1 9 8]\n",
      " [5 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [14  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [15  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [11  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [13  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9  8]\n",
      " [ 5 10  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9  8]\n",
      " [ 5 25  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [15  4  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [15 21  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [13  7  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [13 22  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9  8]\n",
      " [ 5 25  3]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9  8]\n",
      " [ 5 25  9]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [15 21  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [15 21 16]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [13 22  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [13 22 10]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9  8]\n",
      " [ 5 25  9]\n",
      " [ 6  0  0]]\n",
      "iteration..\n",
      "[[ 1  9  8]\n",
      " [ 5 25  9]\n",
      " [ 6  0  0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [15 21 16]\n",
      " [ 6  0  0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [15 21 16]\n",
      " [ 6  0  0]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [13 22 10]\n",
      " [ 6  0  0]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [13 22 10]\n",
      " [ 6  0  0]]\n",
      "iteration..\n",
      "[[ 1  9  8]\n",
      " [ 5 25  9]\n",
      " [ 6  5  0]]\n",
      "iteration..\n",
      "[[ 1  9  8]\n",
      " [ 5 25  9]\n",
      " [ 6 14  0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [15 21 16]\n",
      " [ 6  2  0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [15 21 16]\n",
      " [ 6  5  0]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [13 22 10]\n",
      " [ 6 14  0]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [13 22 10]\n",
      " [ 6 20  0]]\n",
      "iteration..\n",
      "[[ 1  9  8]\n",
      " [ 5 25  9]\n",
      " [ 6 14  1]]\n",
      "iteration..\n",
      "[[ 1  9  8]\n",
      " [ 5 25  9]\n",
      " [ 6 14  1]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [15 21 16]\n",
      " [ 6  5  0]]\n",
      "iteration..\n",
      "[[ 7 12  0]\n",
      " [15 21 16]\n",
      " [ 6  5 12]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [13 22 10]\n",
      " [ 6 20  4]]\n",
      "iteration..\n",
      "[[ 5 10  8]\n",
      " [13 22 10]\n",
      " [ 6 20  7]]\n",
      "iteration..\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[1 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[4 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[7 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[3 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[5 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[1 3 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[1 9 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[7 8 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[5 6 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[ 5 16  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[1 9 6]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 16  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 2  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 8  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [ 2  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [12  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [ 2  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [10  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 8  5  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 8 23  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [12  4  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [12 12  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [10  8  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [10 23  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 8 23  2]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 8 23  2]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [12 12  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [12 12 16]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [10 23  8]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [10 23 12]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 8 23  2]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 8 23  2]\n",
      " [ 9  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [12 12 16]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [12 12 16]\n",
      " [ 3  0  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [10 23 12]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [10 23 12]\n",
      " [ 6  0  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 8 23  2]\n",
      " [ 9  0  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 8 23  2]\n",
      " [ 9  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [12 12 16]\n",
      " [ 3  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [12 12 16]\n",
      " [ 3 12  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [10 23 12]\n",
      " [ 6  0  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [10 23 12]\n",
      " [ 6  3  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 8 23  2]\n",
      " [ 9  0  0]]\n",
      "iteration..\n",
      "[[ 1  9 14]\n",
      " [ 8 23  2]\n",
      " [ 9  0  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [12 12 16]\n",
      " [ 3 12  0]]\n",
      "iteration..\n",
      "[[ 7 20  0]\n",
      " [12 12 16]\n",
      " [ 3 12  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [10 23 12]\n",
      " [ 6  3  0]]\n",
      "iteration..\n",
      "[[ 5 16  8]\n",
      " [10 23 12]\n",
      " [ 6  3  0]]\n",
      "iteration..\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[4 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[12  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[4 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[ 4 12  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[12  0  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[8 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "iteration..\n",
      "[[ 8 16  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 4 12  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 8 16  0]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [ 0  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [15  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [ 8  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [21  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [ 6  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [20  0  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [15  6  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [15 26  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [21 12  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [21 38  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [20  9  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [20 31  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [15 26  9]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [15 26 13]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [21 38  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [21 38 16]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [20 31  0]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [20 31  8]\n",
      " [ 0  0  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [15 26 13]\n",
      " [ 4  0  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [15 26 13]\n",
      " [13  0  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [21 38 16]\n",
      " [ 4  0  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [21 38 16]\n",
      " [ 7  0  0]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [20 31  8]\n",
      " [ 4  0  0]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [20 31  8]\n",
      " [10  0  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [15 26 13]\n",
      " [13  8  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [15 26 13]\n",
      " [13 14  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [21 38 16]\n",
      " [ 7  6  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [21 38 16]\n",
      " [ 7 20  0]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [20 31  8]\n",
      " [10 14  0]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [20 31  8]\n",
      " [10 21  0]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [15 26 13]\n",
      " [13 14  3]]\n",
      "iteration..\n",
      "[[ 4 12  8]\n",
      " [15 26 13]\n",
      " [13 14  3]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [21 38 16]\n",
      " [ 7 20  0]]\n",
      "iteration..\n",
      "[[12 12  0]\n",
      " [21 38 16]\n",
      " [ 7 20  8]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [20 31  8]\n",
      " [10 21 12]]\n",
      "iteration..\n",
      "[[ 8 16  8]\n",
      " [20 31  8]\n",
      " [10 21 14]]\n"
     ]
    }
   ],
   "source": [
    "from layers import conv_forward_naive\n",
    "\n",
    "def conv_backward_naive(dout, cache):\n",
    "  \"\"\"\n",
    "  A naive implementation of the backward pass for a convolutional layer.\n",
    "\n",
    "  Inputs:\n",
    "  - dout: Upstream derivatives.\n",
    "  - cache: A tuple of (x, w, b, conv_param) as in conv_forward_naive\n",
    "\n",
    "  Returns a tuple of:\n",
    "  - dx: Gradient with respect to x\n",
    "  - dw: Gradient with respect to w\n",
    "  - db: Gradient with respect to b\n",
    "  \"\"\"\n",
    "  print \"In\"\n",
    "  dx, dw, db = None, None, None\n",
    "  #############################################################################\n",
    "  # TODO: Implement the convolutional backward pass.                          #\n",
    "  #############################################################################\n",
    "  x, w, b, conv_param = cache\n",
    "  pad = conv_param['pad'] \n",
    "  stride = conv_param['stride']\n",
    "  \n",
    "  N, F, H_1, W_1 = dout.shape\n",
    "  F, C, HH, WW = w.shape\n",
    "  N, C, H, W = x.shape\n",
    "  \n",
    "  inv_pad = ((W - 1) * stride + WW - W_1) / 2\n",
    "  dout_pad = np.zeros((N, F, H_1+2*inv_pad, W_1+2*inv_pad))\n",
    "  # padding dout\n",
    "  for n in xrange(N):\n",
    "    for f in xrange(F):\n",
    "      dout_pad[n,f,:,:] = np.pad(dout[n,f,:,:], inv_pad, 'constant')\n",
    "\n",
    "  dx = np.zeros_like(x)\n",
    "  # convolution, naive implementation\n",
    "  for n in xrange(N):\n",
    "      ii = 0\n",
    "      for i in xrange(H):\n",
    "          jj = 0\n",
    "          for j in xrange(W):\n",
    "              for c in xrange(C):\n",
    "                  for f in xrange(F):\n",
    "                      dx[n, c, i, j] += np.sum(dout_pad[n, f, ii:ii+HH, jj:jj+WW] * w[f, c, :, :])\n",
    "                      print \"iteration..\"\n",
    "                      print dx[n, c, :, :]\n",
    "              jj += stride\n",
    "                  # print \"ii=%s, jj=%s\"% (ii, jj)\n",
    "          ii += stride\n",
    "                                 \n",
    "  \n",
    "  #############################################################################\n",
    "  #                             END OF YOUR CODE                              #\n",
    "  #############################################################################\n",
    "  return dx, dw, db\n",
    "\n",
    "\n",
    "x = np.random.randint(0,5,(4, 3, 3, 3))\n",
    "w = np.random.randint(0,5,(2, 3, 2, 2))\n",
    "b = np.random.randint(0,5,(2,))\n",
    "dout = np.random.randint(0,5,(4, 2, 2, 2))\n",
    "conv_param = {'stride': 1, 'pad': 0}\n",
    "\n",
    "\n",
    "out, cache = conv_forward_naive(x, w, b, conv_param)\n",
    "print \"dout\"\n",
    "print dout[0,0,:,:]\n",
    "print \"weight\"\n",
    "print w[:,0,:,:]\n",
    "dx, dw, db = conv_backward_naive(dout, cache)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from cs231n.layers import *\n",
    "from cs231n.fast_layers import *\n",
    "from cs231n.layer_utils import *\n",
    "\n",
    "\n",
    "class ThreeLayerConvNet(object):\n",
    "  \"\"\"\n",
    "  A three-layer convolutional network with the following architecture:\n",
    "  \n",
    "  conv - relu - 2x2 max pool - affine - relu - affine - softmax\n",
    "  \n",
    "  The network operates on minibatches of data that have shape (N, C, H, W)\n",
    "  consisting of N images, each with height H and width W and with C input\n",
    "  channels.\n",
    "  \"\"\"\n",
    "  \n",
    "  def __init__(self, input_dim=(3, 32, 32), num_filters=32, filter_size=7,\n",
    "               hidden_dim=100, num_classes=10, weight_scale=1e-3, reg=0.0,\n",
    "               dtype=np.float32):\n",
    "    \"\"\"\n",
    "    Initialize a new network.\n",
    "    \n",
    "    Inputs:\n",
    "    - input_dim: Tuple (C, H, W) giving size of input data\n",
    "    - num_filters: Number of filters to use in the convolutional layer\n",
    "    - filter_size: Size of filters to use in the convolutional layer\n",
    "    - hidden_dim: Number of units to use in the fully-connected hidden layer\n",
    "    - num_classes: Number of scores to produce from the final affine layer.\n",
    "    - weight_scale: Scalar giving standard deviation for random initialization\n",
    "      of weights.\n",
    "    - reg: Scalar giving L2 regularization strength\n",
    "    - dtype: numpy datatype to use for computation.\n",
    "    \"\"\"\n",
    "    self.params = {}\n",
    "    self.reg = reg\n",
    "    self.dtype = dtype\n",
    "    \n",
    "    ############################################################################\n",
    "    # TODO: Initialize weights and biases for the three-layer convolutional    #\n",
    "    # network. Weights should be initialized from a Gaussian with standard     #\n",
    "    # deviation equal to weight_scale; biases should be initialized to zero.   #\n",
    "    # All weights and biases should be stored in the dictionary self.params.   #\n",
    "    # Store weights and biases for the convolutional layer using the keys 'W1' #\n",
    "    # and 'b1'; use keys 'W2' and 'b2' for the weights and biases of the       #\n",
    "    # hidden affine layer, and keys 'W3' and 'b3' for the weights and biases   #\n",
    "    # of the output affine layer.                                              #\n",
    "    ############################################################################\n",
    "    C, H, W = input_dim\n",
    "    HH, WW = filter_size, filter_size\n",
    "    F = num_filters\n",
    "    \n",
    "    self.params['W1'] = weight_scale * np.random.randn(F,C,HH,WW)\n",
    "    self.params['b1'] = np.zeros(F)\n",
    "    affine1_dim = (H/2) * (W/2) * (num_filters)\n",
    "    self.params['W2'] = weight_scale * np.random.randn(affine1_dim, hidden_dim)\n",
    "    self.params['b2'] = np.zeros(hidden_dim)\n",
    "    self.params['W3'] = weight_scale * np.random.randn(hidden_dim, num_classes)\n",
    "    self.params['b3'] = np.zeros(num_classes)\n",
    "    ############################################################################\n",
    "    #                             END OF YOUR CODE                             #\n",
    "    ############################################################################\n",
    "\n",
    "    for k, v in self.params.iteritems():\n",
    "      self.params[k] = v.astype(dtype)\n",
    "     \n",
    " \n",
    "  def loss(self, X, y=None):\n",
    "    \"\"\"\n",
    "    Evaluate loss and gradient for the three-layer convolutional network.\n",
    "    \n",
    "    Input / output: Same API as TwoLayerNet in fc_net.py.\n",
    "    \"\"\"\n",
    "    W1, b1 = self.params['W1'], self.params['b1']\n",
    "    W2, b2 = self.params['W2'], self.params['b2']\n",
    "    W3, b3 = self.params['W3'], self.params['b3']\n",
    "    \n",
    "    # pass conv_param to the forward pass for the convolutional layer\n",
    "    filter_size = W1.shape[2]\n",
    "    conv_param = {'stride': 1, 'pad': (filter_size - 1) / 2}\n",
    "\n",
    "    # pass pool_param to the forward pass for the max-pooling layer\n",
    "    pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}\n",
    "\n",
    "    scores = None\n",
    "    ############################################################################\n",
    "    # TODO: Implement the forward pass for the three-layer convolutional net,  #\n",
    "    # computing the class scores for X and storing them in the scores          #\n",
    "    # variable.                                                                #\n",
    "    ############################################################################\n",
    "    # forward pass\n",
    "    layer1, cache1 = conv_relu_pool_forward(X, W1, b1, conv_param, pool_param)\n",
    "    layer2, cache2 = affine_relu_forward(layer1, W2, b2)\n",
    "    layer3, cache3 = affine_forward(layer2, W3, b3)\n",
    "    scores = layer3\n",
    "    ############################################################################\n",
    "    #                             END OF YOUR CODE                             #\n",
    "    ############################################################################\n",
    "    \n",
    "    if y is None:\n",
    "      return scores\n",
    "    \n",
    "    loss, grads = 0, {}\n",
    "    ############################################################################\n",
    "    # TODO: Implement the backward pass for the three-layer convolutional net, #\n",
    "    # storing the loss and gradients in the loss and grads variables. Compute  #\n",
    "    # data loss using softmax, and make sure that grads[k] holds the gradients #\n",
    "    # for self.params[k]. Don't forget to add L2 regularization!               #\n",
    "    ############################################################################\n",
    "    loss, dloss = softmax_loss(scores, y)\n",
    "    reg = self.reg\n",
    "    loss += 0.5 * reg * (np.sum(W1*W1) + np.sum(W2*W2) + np.sum(W3*W3))\n",
    "    #backward pass\n",
    "    dlayer3, dW3, db3 = affine_backward(dloss, cache3)\n",
    "    dlayer2, dW2, db2 = affine_relu_backward(dlayer3, cache2)\n",
    "    dx, dW1, db1 = conv_relu_pool_backward(dlayer2, cache1)\n",
    "    \n",
    "    \n",
    "    grads['W1'] = dW1 + reg * W1\n",
    "    grads['b1'] = db1\n",
    "    grads['W2'] = dW2 + reg * W2\n",
    "    grads['b2'] = db2\n",
    "    grads['W3'] = dW3 + reg * W3\n",
    "    grads['b3'] = db3\n",
    "    ############################################################################\n",
    "    #                             END OF YOUR CODE                             #\n",
    "    ############################################################################\n",
    "    \n",
    "    return loss, grads\n",
    "  \n",
    "  \n",
    "pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
